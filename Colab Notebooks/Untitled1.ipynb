{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7ye4oEYuiF1nEZ7D6N1gW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Importing librairies\n","\n","import pandas as pd \n","import numpy as np\n","\n","# Scikit-learn library: For SVM\n","from sklearn import preprocessing\n","from sklearn.metrics import confusion_matrix\n","from sklearn import svm\n","\n","import itertools\n","\n","# Matplotlib library to plot the charts\n","import matplotlib.pyplot as plt\n","import matplotlib.mlab as mlab\n","\n","# Library for the statistic data vizualisation\n","import seaborn\n","\n","%matplotlib inline"],"metadata":{"id":"12gsnFxvfGWo","executionInfo":{"status":"ok","timestamp":1678602208709,"user_tz":-330,"elapsed":2520,"user":{"displayName":"PANGA SAI NARENDRA 21BCE9868","userId":"11781088589423733827"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('') # Reading the file .csv\n","df = pd.DataFrame(data) # Converting data to Panda DataFrame"],"metadata":{"id":"dkfx9fNkfLPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(data) # Converting data to Panda DataFrame"],"metadata":{"id":"VqjB9JU-f8qO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe() # Description of statistic features (Sum, Average, Variance, minimum, 1st quartile, 2nd quartile, 3rd Quartile and Maximum)"],"metadata":{"id":"Z34FFug7f9rK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_fraud = df[df['Class'] == 1] # Recovery of fraud data\n","plt.figure(figsize=(15,10))\n","plt.scatter(df_fraud['Time'], df_fraud['Amount']) # Display fraud amounts according to their time\n","plt.title('Scratter plot amount fraud')\n","plt.xlabel('Time')\n","plt.ylabel('Amount')\n","plt.xlim([0,175000])\n","plt.ylim([0,2500])\n","plt.show()"],"metadata":{"id":"bHWrC_otgBXC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_big_fraud = df_fraud[df_fraud['Amount'] > 1000].shape[0] # Recovery of frauds over 1000\n","print('There are only '+ str(nb_big_fraud) + ' frauds where the amount was bigger than 1000 over ' + str(df_fraud.shape[0]) + ' frauds')"],"metadata":{"id":"ZbZ65YWGgD_9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["number_fraud = len(data[data.Class == 1])\n","number_no_fraud = len(data[data.Class == 0])\n","print('There are only '+ str(number_fraud) + ' frauds in the original dataset, even though there are ' + str(number_no_fraud) +' no frauds in the dataset.')"],"metadata":{"id":"Eu27dwKngGna"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"The accuracy of the classifier then would be : \"+ str((284315-492)/284315)+ \" which is the number of good classification over the number of tuple to classify\")"],"metadata":{"id":"tRcbR3_agI8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_corr = df.corr() # Calculation of the correlation coefficients in pairs, with the default method:\n","                    # Pearson, Standard Correlation Coefficient"],"metadata":{"id":"qCa2W4rFgLm9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(15,10))\n","seaborn.heatmap(df_corr, cmap=\"YlGnBu\") # Displaying the Heatmap\n","seaborn.set(font_scale=2,style='white')\n","\n","plt.title('Heatmap correlation')\n","plt.show()"],"metadata":{"id":"o-HyzM3WgO5F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rank = df_corr['Class'] # Retrieving the correlation coefficients per feature in relation to the feature class\n","df_rank = pd.DataFrame(rank) \n","df_rank = np.abs(df_rank).sort_values(by='Class',ascending=False) # Ranking the absolute values of the coefficients\n","                                                                  # in descending order\n","df_rank.dropna(inplace=True) # Removing Missing Data (not a number"],"metadata":{"id":"M7l8mHK9gSDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We seperate ours data in two groups : a train dataset and a test dataset\n","\n","# First we build our train dataset\n","df_train_all = df[0:150000] # We cut in two the original dataset\n","df_train_1 = df_train_all[df_train_all['Class'] == 1] # We seperate the data which are the frauds and the no frauds\n","df_train_0 = df_train_all[df_train_all['Class'] == 0]\n","print('In this dataset, we have ' + str(len(df_train_1)) +\" frauds so we need to take a similar number of non-fraud\")\n","\n","df_sample=df_train_0.sample(300)\n","df_train = df_train_1.append(df_sample) # We gather the frauds with the no frauds. \n","df_train = df_train.sample(frac=1) # Then we mix our dataset"],"metadata":{"id":"DBa2do9bgVfr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = df_train.drop(['Time', 'Class'],axis=1) # We drop the features Time (useless), and the Class (label)\n","y_train = df_train['Class'] # We create our label\n","X_train = np.asarray(X_train)\n","y_train = np.asarray(y_train)"],"metadata":{"id":"Vz0O-p7YgZBF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["############################## with all the test dataset to see if the model learn correctly ##################\n","df_test_all = df[150000:]\n","\n","X_test_all = df_test_all.drop(['Time', 'Class'],axis=1)\n","y_test_all = df_test_all['Class']\n","X_test_all = np.asarray(X_test_all)\n","y_test_all = np.asarray(y_test_all)"],"metadata":{"id":"HfdM6Kk7gbRG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_rank = df_train[df_rank.index[1:11]] # We take the first ten ranked features\n","X_train_rank = np.asarray(X_train_rank)"],"metadata":{"id":"2xpJqEB4geD6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["############################## with all the test dataset to see if the model learn correctly ##################\n","X_test_all_rank = df_test_all[df_rank.index[1:11]]\n","X_test_all_rank = np.asarray(X_test_all_rank)\n","y_test_all = np.asarray(y_test_all)"],"metadata":{"id":"GPjtmS4uggiq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names=np.array(['0','1']) # Binary label, Class = 1 (fraud) and Class = 0 (no fraud)"],"metadata":{"id":"MeZMVyJFgk5o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to plot the confusion Matrix\n","def plot_confusion_matrix(cm, classes,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = 'd' \n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"metadata":{"id":"K5qVXBySglyO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier = svm.SVC(kernel='linear') # We set a SVM classifier, the default SVM Classifier (Kernel = Radial Basis Function)"],"metadata":{"id":"lRhn2XDmg8vB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier.fit(X_train, y_train) # Then we train our model, with our balanced data train."],"metadata":{"id":"ClKDTOSxhDLx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction_SVM_all = classifier.predict(X_test_all) #And finally, we predict our data test."],"metadata":{"id":"XDGT328zhECq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(y_test_all, prediction_SVM_all)\n","plot_confusion_matrix(cm,class_names)"],"metadata":{"id":"9-9jX2TZhHXt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Our criterion give a result of ' \n","      + str( ( (cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1])) + 4 * cm[1][1]/(cm[1][0]+cm[1][1])) / 5))"],"metadata":{"id":"uCKYMW0uhJda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')\n","print('\\nSo, the probability to detect a fraud is ' + str(cm[1][1]/(cm[1][1]+cm[1][0])))\n","print(\"the accuracy is : \"+str((cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1]))))"],"metadata":{"id":"n48viuHghMiA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier.fit(X_train_rank, y_train) # Then we train our model, with our balanced data train.\n","prediction_SVM = classifier.predict(X_test_all_rank) #And finally, we predict our data test."],"metadata":{"id":"bUJdgaqqhPN8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(y_test_all, prediction_SVM)\n","plot_confusion_matrix(cm,class_names)"],"metadata":{"id":"kLlcFIphhR3V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Our criterion give a result of ' \n","      + str( ( (cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1])) + 4 * cm[1][1]/(cm[1][0]+cm[1][1])) / 5))"],"metadata":{"id":"uFCDF0TahUh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')\n","print('\\nSo, the probability to detect a fraud is ' + str(cm[1][1]/(cm[1][1]+cm[1][0])))\n","print(\"the accuracy is : \"+str((cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1]))))"],"metadata":{"id":"gRuwAfxPhYPl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier_b = svm.SVC(kernel='linear',class_weight={0:0.60, 1:0.40})"],"metadata":{"id":"uRnFwLlohlXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier_b.fit(X_train, y_train) # Then we train our model, with our balanced data train."],"metadata":{"id":"z18oj6J2hmId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction_SVM_b_all = classifier_b.predict(X_test_all) #We predict all the data set."],"metadata":{"id":"sIKT7t4MhohS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(y_test_all, prediction_SVM_b_all)\n","plot_confusion_matrix(cm,class_names)"],"metadata":{"id":"-P4057xyhrpb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Our criterion give a result of ' \n","      + str( ( (cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1])) + 4 * cm[1][1]/(cm[1][0]+cm[1][1])) / 5))"],"metadata":{"id":"YZeUtpe5ht-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')\n","print('\\nSo, the probability to detect a fraud is ' + str(cm[1][1]/(cm[1][1]+cm[1][0])))\n","print(\"the accuracy is : \"+str((cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1]))))"],"metadata":{"id":"joen-md7hxqP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier_b.fit(X_train_rank, y_train) # Then we train our model, with our balanced data train.\n","prediction_SVM = classifier_b.predict(X_test_all_rank) #And finally, we predict our data test."],"metadata":{"id":"DxypLP_Xh0IG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(y_test_all, prediction_SVM)\n","plot_confusion_matrix(cm,class_names)"],"metadata":{"id":"6XajC80wh2sI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Our criterion give a result of ' \n","      + str( ( (cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1])) + 4 * cm[1][1]/(cm[1][0]+cm[1][1])) / 5))"],"metadata":{"id":"G9ELt_gGh4-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')\n","print('\\nSo, the probability to detect a fraud is ' + str(cm[1][1]/(cm[1][1]+cm[1][0])))\n","print(\"the accuracy is : \"+str((cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1]))))"],"metadata":{"id":"kC0-O3qrh7H8"},"execution_count":null,"outputs":[]}]}