{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZf36w00t8l8ToUkJitIF3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Name :- Sai Narendra Panga\n","##Reg N.o :- 21BCE9868"],"metadata":{"id":"LVZ7Q7a5K9z1"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212},"id":"dcBhmjMWKWpa","executionInfo":{"status":"ok","timestamp":1675996345530,"user_tz":-330,"elapsed":29142,"user":{"displayName":"PANGA SAI NARENDRA 21BCE9868","userId":"11781088589423733827"}},"outputId":"7edc375f-2973-4fb9-8513-688ab0cd5084"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-246cb771-d2eb-4f0a-922b-9d77eb330641\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-246cb771-d2eb-4f0a-922b-9d77eb330641\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","Downloading trainplaytennis.zip to /content\n","  0% 0.00/314 [00:00<?, ?B/s]\n","100% 314/314 [00:00<00:00, 317kB/s]\n","trainplaytennis.zip: Skipping, found more recently modified local copy (use --force to force download)\n","Downloading testplaytennis.zip to /content\n","  0% 0.00/272 [00:00<?, ?B/s]\n","100% 272/272 [00:00<00:00, 267kB/s]\n","1.0\n"]}],"source":["!pip install -q kaggle\n","!mkdir -p ~/.kaggle\n","from google.colab import files\n","files.upload()\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 /content ~/.kaggle/kaggle.json\n","!kaggle datasets download -d tareqjoy/trainplaytennis\n","!kaggle datasets download -d tareqjoy/trainplaytennis\n","!unzip -q trainplaytennis.zip -d /content/play\n","!kaggle datasets download -d tareqjoy/testplaytennis\n","!unzip -q testplaytennis.zip -d /content/play/test\n","import pandas as pd\n","import numpy as np #for mathematical calculation\n","train_data_m = pd.read_csv(\"/content/play/PlayTennis.csv\") #importing the dataset from the disk\n","train_data_m.head() #viewing some row of the dataset\n","def calc_total_entropy(train_data, label, class_list):\n","    total_row = train_data.shape[0] #the total size of the dataset\n","    total_entr = 0\n","    for c in class_list: #for each class in the label\n","        total_class_count = train_data[train_data[label] == c].shape[0] #number of the class\n","        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n","        total_entr += total_class_entr #adding the class entropy to the total entropy of the dataset\n","    return total_entr\n","def calc_entropy(feature_value_data, label, class_list):\n","    class_count = feature_value_data.shape[0]\n","    entropy = 0\n","    for c in class_list:\n","        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c\n","        entropy_class = 0\n","        if label_class_count != 0:\n","           probability_class = label_class_count/class_count #probability of the class\n","           entropy_class = - probability_class * np.log2(probability_class) #entropy\n","        entropy += entropy_class\n","    return entropy\n","def calc_info_gain(feature_name, train_data, label, class_list):\n","    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\n","    total_row = train_data.shape[0]\n","    feature_info = 0.0\n","    for feature_value in feature_value_list:\n","        feature_value_data = train_data[train_data[feature_name] == feature_value] #filtering rows with that feature_value\n","        feature_value_count = feature_value_data.shape[0]\n","        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) #calculcating entropy for the feature value\n","        feature_value_probability = feature_value_count/total_row\n","        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\n","    return calc_total_entropy(train_data, label, class_list) - feature_info #calculating information gain by subtracting\n","def find_most_informative_feature(train_data, label, class_list):\n","    feature_list = train_data.columns.drop(label) #finding the feature names in the dataset\n","    #N.B. label is not a feature, so dropping it\n","    max_info_gain = -1\n","    max_info_feature = None\n","    for feature in feature_list: #for each feature in the dataset\n","        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n","        if max_info_gain < feature_info_gain: #selecting feature name with highest information gain\n","            max_info_gain = feature_info_gain\n","            max_info_feature = feature\n","    return max_info_feature\n","def generate_sub_tree(feature_name, train_data, label, class_list):\n","    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) #dictionary of the count of unqiue feature value\n","    tree = {} #sub tree or node\n","    for feature_value, count in feature_value_count_dict.iteritems():\n","        feature_value_data = train_data[train_data[feature_name] == feature_value] #dataset with only feature_name = feature_value\n","        assigned_to_node = False #flag for tracking feature_value is pure class or not\n","        for c in class_list: #for each class\n","            class_count = feature_value_data[feature_value_data[label] == c].shape[0] #count of class c\n","            if class_count == count: #count of (feature_value = count) of class (pure class)\n","                tree[feature_value] = c #adding node to the tree\n","                train_data = train_data[train_data[feature_name] != feature_value] #removing rows with feature_value\n","                assigned_to_node = True\n","        if not assigned_to_node: #not pure class\n","            tree[feature_value] = \"?\" #as feature_value is not a pure class, it should be expanded further,\n","            #so the branch is marking with ?\n","    return tree, train_data\n","def make_tree(root, prev_feature_value, train_data, label, class_list):\n","    if train_data.shape[0] != 0: #if dataset becomes enpty after updating\n","        max_info_feature = find_most_informative_feature(train_data, label, class_list) #most informative feature\n","        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list) #getting tree node and updated dataset\n","        next_root = None\n","        if prev_feature_value != None: #add to intermediate node of the tree\n","            root[prev_feature_value] = dict()\n","            root[prev_feature_value][max_info_feature] = tree\n","            next_root = root[prev_feature_value][max_info_feature]\n","        else: #add to root of the tree\n","            root[max_info_feature] = tree\n","            next_root = root[max_info_feature]\n","        for node, branch in list(next_root.items()): #iterating the tree node\n","            if branch == \"?\": #if it is expandable\n","                feature_value_data = train_data[train_data[max_info_feature] == node] #using the updated dataset\n","                make_tree(next_root, node, feature_value_data, label, class_list) #recursive call with updated dataset\n","def id3(train_data_m, label):\n","    train_data = train_data_m.copy() #getting a copy of the dataset\n","    tree = {} #tree which will be updated\n","    class_list = train_data[label].unique() #getting unqiue classes of the label\n","    make_tree(tree, None, train_data, label, class_list) #start calling recursion\n","    return tree\n","tree = id3(train_data_m, 'Play Tennis')\n","def predict(tree, instance):\n","    if not isinstance(tree, dict): #if it is leaf node\n","        return tree #return the value\n","    else:\n","        root_node = next(iter(tree)) #getting first key/feature name of the dictionary\n","        feature_value = instance[root_node] #value of the feature\n","        if feature_value in tree[root_node]: #checking the feature value in current tree node\n","            return predict(tree[root_node][feature_value], instance) #goto next feature\n","        else:\n","            return None\n","def evaluate(tree, test_data_m, label):\n","    correct_preditct = 0\n","    wrong_preditct = 0\n","    for index, row in test_data_m.iterrows(): #for each row in the dataset\n","        result = predict(tree, test_data_m.iloc[index]) #predict the row\n","        if result == test_data_m[label].iloc[index]: #predicted value and expected value is same or not\n","            correct_preditct += 1 #increase correct count\n","        else:\n","            wrong_preditct += 1 #increase incorrect count\n","    accuracy = correct_preditct / (correct_preditct + wrong_preditct) #calculating accuracy\n","    return accuracy\n","test_data_m = pd.read_csv(\"/content/play/test/PlayTennis.csv\") #importing test dataset into dataframe\n","accuracy = evaluate(tree, test_data_m, 'Play Tennis') #evaluating the test dataset\n","print(accuracy)"]}]}